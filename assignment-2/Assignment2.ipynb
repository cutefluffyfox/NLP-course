{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIgM6C9HYUhm"
   },
   "source": [
    "# Context-sensitive Spelling Correction\n",
    "\n",
    "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
    "\n",
    "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
    "\n",
    "Useful links:\n",
    "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
    "- [Norvig's dataset](https://norvig.com/big.txt)\n",
    "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
    "\n",
    "Grading:\n",
    "- 60 points - Implement spelling correction\n",
    "- 20 points - Justify your decisions\n",
    "- 20 points - Evaluate on a test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-vb8yFOGRDF"
   },
   "source": [
    "## Implement context-sensitive spelling correction\n",
    "\n",
    "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
    "\n",
    "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
    "\n",
    "You may also want to implement:\n",
    "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
    "- some recent (or not very recent) paper on this topic,\n",
    "- solution which takes into account keyboard layout and associated misspellings,\n",
    "- efficiency improvement to make the solution faster,\n",
    "- any other idea of yours to improve the Norvig’s solution.\n",
    "\n",
    "IMPORTANT:  \n",
    "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
    "- Your implementation\n",
    "- Analysis of why the implemented approach is suggested\n",
    "- Improvements of the original approach that you have chosen to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "class NGramLanguageModel:\n",
    "    \"\"\"\n",
    "    Base class for any n-gram-based language model\n",
    "    \"\"\"\n",
    "\n",
    "    n = -1  # `n` in n-gram\n",
    "    candidates = defaultdict(list)  # possible next words based on context\n",
    "    vocab = defaultdict(int)  # vocab with frequencies\n",
    "    total = 0  # total frequency count\n",
    "    has_pad = False  # whether LM support <pad> token\n",
    "\n",
    "    def get(self, context: tuple[str]) -> list[tuple[str, int]]:\n",
    "        \"\"\"\n",
    "        Get all possible next words based on context\n",
    "\n",
    "        :param context:  tuple of string representing words that came earlier\n",
    "        :return:         all possible words that can come next with their frequencies\n",
    "        \"\"\"\n",
    "\n",
    "        return self.candidates[context]\n",
    "\n",
    "    def get_vocab_freq(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        Get frequency in vocab of a given word\n",
    "\n",
    "        :param word:  word to get frequency count to\n",
    "        :return:      frequency count (would be 0 if not in vocab)\n",
    "        \"\"\"\n",
    "\n",
    "        return self.vocab[word]\n",
    "\n",
    "    def get_total_count(self) -> int:\n",
    "        \"\"\"\n",
    "        Get total number of words (with frequencies) in vocab\n",
    "\n",
    "        :return:  total number of words\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MoQeEsZvHvvi"
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModelFromFile(NGramLanguageModel):\n",
    "    \"\"\"\n",
    "    N-gram based LM that could be initialized from frequency count\n",
    "\n",
    "    Examples of the file structure & input data:\n",
    "        * https://www.ngrams.info/download_coca.asp\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str, do_pad: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize model\n",
    "\n",
    "        :param file_path:  path to the n-gram based file\n",
    "        :param do_pad:     whether to add <pad> token & support smaller n-grams\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize ngram `n` and `has_pad`\n",
    "        self.n = -1\n",
    "        self.has_pad = do_pad\n",
    "\n",
    "        # init base class variables\n",
    "        self.candidates = defaultdict(list)\n",
    "        self.vocab = defaultdict(int)\n",
    "        self.total = 0\n",
    "\n",
    "        # calculate statistics\n",
    "        self.__parse_file(file_path)\n",
    "        self.__aggregate()\n",
    "\n",
    "    def __parse_file(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Hidden method that parse given file and load data to\n",
    "        `self.candidates` and `self.vocab`\n",
    "\n",
    "        :param file_path:  path where the file is located (note: latin-1 encoding will be used)\n",
    "        \"\"\"\n",
    "\n",
    "        with open(file_path, 'r', encoding='latin-1') as file:\n",
    "            # each like has format `# token1 token2 ... tokenN`\n",
    "            for line in file:\n",
    "                # parse and transform\n",
    "                cnt, *data = line.strip().split()\n",
    "                cnt = int(cnt)\n",
    "\n",
    "                # get ngram and add it to candidates\n",
    "                for *context, pred in self.__sub_ngram(data, self.has_pad):\n",
    "                    self.candidates[tuple(context)].append((pred, cnt))\n",
    "\n",
    "                # update word count for each unique word in data\n",
    "                for word in data:\n",
    "                    self.vocab[word] += cnt\n",
    "                    self.total += cnt\n",
    "\n",
    "            # define `n` in ngram from candidates\n",
    "            self.n = 1 + len(tuple(self.candidates.keys())[0])\n",
    "\n",
    "    def __aggregate(self):\n",
    "        \"\"\"\n",
    "        Hidden method that aggregates same values in candidates\n",
    "        \"\"\"\n",
    "\n",
    "        for key in tuple(self.candidates.keys()):\n",
    "\n",
    "            # if same key present several times - we will combine them into one\n",
    "            df = defaultdict(int)\n",
    "            for word, cnt in self.candidates[key]:\n",
    "                df[word] += cnt\n",
    "\n",
    "            # update candidates with aggregated frequency list\n",
    "            self.candidates[key] = list(df.items())\n",
    "\n",
    "    @staticmethod\n",
    "    def __sub_ngram(data: tuple[str], pad: bool = True) -> tuple[str]:\n",
    "        \"\"\"\n",
    "        Hidden method that generates ngram based on given text:\n",
    "            * `n` is determined as len(data) - 1 (due to file format)\n",
    "            * `pad` represents whether we want to add <pad> tokens to   \\\n",
    "                beginning or not, it is beneficial if mistake is in the \\\n",
    "                first word\n",
    "\n",
    "        :param data:  token list to generate ngrams from\n",
    "        :param pad:   whether to add <pad> or no\n",
    "        :return:      yields possible ngrams\n",
    "        \"\"\"\n",
    "        \n",
    "        n = len(data)\n",
    "        for i in range(1 if pad else n, n + 1):\n",
    "            yield ('<pad>',) * (n - i) + tuple(data[:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "from typing import Generator, Any\n",
    "\n",
    "\n",
    "class NorvigSolution:\n",
    "    \"\"\"\n",
    "    Norvig solution taken and slightly modified from [1].\n",
    "\n",
    "    [1] - https://norvig.com/spell-correct.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Init model based on frequency file\n",
    "\n",
    "        :param file_path:  path to the n-gram based file (same as in NGramLanguageModelFromFile)\n",
    "        \"\"\"\n",
    "\n",
    "        # init key components\n",
    "        self.words = defaultdict(int)\n",
    "        self.total = 0\n",
    "\n",
    "        # load data\n",
    "        self.__parse_file(file_path)\n",
    "\n",
    "    def __parse_file(self, file_path: str):\n",
    "        \"\"\"Hidden method that parse and load data to `self.words`\"\"\"\n",
    "\n",
    "        with open(file_path, 'r', encoding='latin-1') as file:\n",
    "            # each like has format `# token1 token2 ... tokenN`\n",
    "            for line in file:\n",
    "                # parse and transform\n",
    "                cnt, *data = line.strip().split()\n",
    "                cnt = int(cnt)\n",
    "\n",
    "                # update word count for each word in data\n",
    "                for word in data:\n",
    "                    self.words[word] += cnt\n",
    "                    self.total += cnt\n",
    "\n",
    "    def __word_prob(self, word: str) -> float:\n",
    "        \"\"\"Get word probability to be observed\"\"\"\n",
    "        return self.words[word] / self.total\n",
    "\n",
    "    def correction(self, word: str) -> str:\n",
    "        \"\"\"Most probable spelling correction for word\"\"\"\n",
    "        return max(self.candidates(word), key=self.__word_prob)\n",
    "\n",
    "    def candidates(self, word: str) -> list[str] or set[str]:\n",
    "        \"\"\"Generate possible spelling corrections for word\"\"\"\n",
    "        return self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word]\n",
    "\n",
    "    def known(self, words) -> set[str]:\n",
    "        \"\"\"The subset of `words` that appear in the dictionary of `self.words`\"\"\"\n",
    "        return set(w for w in words if w in self.words)\n",
    "\n",
    "    @staticmethod\n",
    "    def edits1(word: str) -> set[str]:\n",
    "        \"\"\"All edits that are one edit away from `word`\"\"\"\n",
    "\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    @staticmethod\n",
    "    def edits2(word: str) -> Generator[str, Any, None]:\n",
    "        \"\"\"All edits that are two edits away from `word`\"\"\"\n",
    "        return (e2 for e1 in NorvigSolution.edits1(word) for e2 in NorvigSolution.edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpellCorrection:\n",
    "    \"\"\"\n",
    "    Apply spelling correction algorithm based on n-gram model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lm: NGramLanguageModel, edit_lim: int = 2, freq_threshold: float = 1e-5):\n",
    "        \"\"\"\n",
    "        Initialize model hyperparameters\n",
    "\n",
    "        :param lm:              fitted n-gram language model\n",
    "        :param edit_lim:        maximum edit distance\n",
    "        :param freq_threshold:  minimum threshold needed to be achieved for word not to be corrected\n",
    "        \"\"\"\n",
    "\n",
    "        # safe all data\n",
    "        self.lm = lm\n",
    "        self.edit_lim = edit_lim\n",
    "        self.freq_threshold = freq_threshold\n",
    "\n",
    "    def check_correct(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Check spelling and correct if any mistakes found.\n",
    "        Text should be formatted as sequence of tokens separated\n",
    "        by space symbol (either space, tab)\n",
    "\n",
    "        :param text:  text where to check spelling\n",
    "        :return:      transformed text (ideally with corrected mistakes)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.lm.has_pad:\n",
    "            # if lm support pad, add it to beginning\n",
    "            correct = ['<pad>'] * (self.lm.n - 1)\n",
    "            start_idx = 0\n",
    "        else:\n",
    "            # otherwise consider first n-tokens as correct\n",
    "            correct = text.lower().split()[:self.lm.n - 1]\n",
    "            start_idx = self.lm.n - 1\n",
    "\n",
    "        for pred in text.lower().split()[start_idx:]:\n",
    "            # determine context (last n-1)\n",
    "            context = tuple(correct[-(self.lm.n - 1):])\n",
    "\n",
    "            # check and correct based & context\n",
    "            correct.append(self.__correct_based_on_context(context, pred))\n",
    "\n",
    "        # return corrected text & remove <pad> if needed\n",
    "        return ' '.join(correct[self.lm.n - 1:] if self.lm.has_pad else correct)\n",
    "\n",
    "    def __pred_prob(self, context: tuple[str], pred: str) -> float:\n",
    "        \"\"\"\n",
    "        Hidden method that gives probability of\n",
    "        finding `pred` after given `context`\n",
    "\n",
    "        :param context:  tuple of tokens representing context\n",
    "        :param pred:     word to count probability for\n",
    "        :return:         probability of encountering `pred` after `context`\n",
    "        \"\"\"\n",
    "\n",
    "        # get all possible words & calculate total frequency\n",
    "        possibilities = self.lm.get(context)\n",
    "        total = sum(map(lambda p: p[1], possibilities))\n",
    "\n",
    "        # find `pred` and return probability\n",
    "        for word, freq in possibilities:\n",
    "            if word == pred:\n",
    "                return freq / total\n",
    "\n",
    "        # if not found, return 0 (this could be improved!)\n",
    "        return 0\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def __correct_based_on_context(self, context: tuple[str], pred: str) -> str:\n",
    "        \"\"\"\n",
    "        Hidden method that corrects `pred` given the context:\n",
    "            * if `pred` satisfy `self.freq_threshold` consider it correct\n",
    "            * otherwise make edits & search them in ngram\n",
    "                1. main idea is to consider `min edit, most frequent` candidate as correct\n",
    "                2. if no ngram edit found, consider raw vocab\n",
    "                3. if vocab is also empty, consider original `pred` as correct\n",
    "\n",
    "        :param context:  tuple of tokens representing context\n",
    "        :param pred:     word to analyze spelling for\n",
    "        :return:         'corrected' best candidate\n",
    "        \"\"\"\n",
    "\n",
    "        # if next word probability satisfy threashold, just consider it correct\n",
    "        if self.__pred_prob(context, pred) > self.freq_threshold:\n",
    "            return pred\n",
    "\n",
    "        # otherwise get all possible next words\n",
    "        possibilities = dict()\n",
    "        for (word, cnt) in self.lm.get(context):\n",
    "            possibilities[word] = cnt\n",
    "\n",
    "        # get all corrections from `1` edit to `edit_lim`\n",
    "        edits = [{pred}]\n",
    "        for i in range(self.edit_lim):\n",
    "            # get all 'possible' edits at distance i+1\n",
    "            edits.append({edit for edit_word in edits[i] for edit in self.edits1(edit_word)})\n",
    "            edits[-1].add(pred)  # give original word a chance (makes sense only when freq_threshold > 0)\n",
    "\n",
    "            # determine 'correct' answer as most frequent word from 'edits'\n",
    "            ans = (pred, -1)\n",
    "            for edit in edits[i + 1]:\n",
    "                if possibilities.get(edit, -1) > ans[1]:\n",
    "                    ans = (edit, possibilities[edit])\n",
    "\n",
    "            # if new answer found, consider it correct (\"min edit, most frequent\" policy)\n",
    "            if ans[1] != -1:\n",
    "                return ans[0]\n",
    "\n",
    "        # if after editing nothing found, consider raw frequencies\n",
    "        ans = (pred, 0)\n",
    "        for edit_set in edits:\n",
    "            for edit in edit_set:\n",
    "                if self.lm.get_vocab_freq(edit) > ans[1]:\n",
    "                    ans = (edit, self.lm.get_vocab_freq(edit))\n",
    "\n",
    "            # if new answer found, consider it correct (same \"min edit, most frequent\" idea)\n",
    "            if ans[1] > 0:\n",
    "                return ans[0]\n",
    "\n",
    "        # if still nothing found, consider original prediction as correct\n",
    "        return pred\n",
    "\n",
    "    @staticmethod\n",
    "    def edits1(word: str) -> set[str]:\n",
    "        \"\"\"\n",
    "        All edits that are one edit away from `word`.\n",
    "        Code taken from https://norvig.com/spell-correct.html\n",
    "\n",
    "        :param word:  word to modify\n",
    "        :return:      set of possible modifications\n",
    "        \"\"\"\n",
    "\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model and spell-checker\n",
    "model = NGramLanguageModelFromFile('data/bigrams.txt', do_pad=True)\n",
    "sp = SpellCorrection(model, edit_lim=1, freq_threshold=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oML-5sJwGRLE"
   },
   "source": [
    "## Justify your decisions\n",
    "\n",
    "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
    "- Which ngram dataset to use\n",
    "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
    "- Beam search parameters\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xb_twOmVsC6"
   },
   "source": [
    "### Dataset decision\n",
    "\n",
    "First of all I want to make some comments regarding dataset. The main problems I faced are:\n",
    "1. It takes a lot of time to count ngram frequencies on large corpora\n",
    "2. There are no* (maybe? I struggled to find) free, large, general-purpose frequencies count online\n",
    "\n",
    "Let's discuss details. The first point is that is takes unreasonable amount of time to calculate good general-purpose ngrams. Finding large texts is not a problem, as thouthands of data samples are available online, there even exists some benchmarks for spell-correction problem (for example, [Billion Word Benchmark](https://paperswithcode.com/dataset/billion-word-benchmark)). The main downside is that to calculate good general-purpose ngrams we need to analyze a lot of text, and ideally the more text we feed, the more robust model will be. But even for small datasets such as [Norvig data](https://norvig.com/big.txt) it took me 20 seconds to calculate all statistics (it resulted in bad dependencies where metric was worther than baseline). If we scale that data up to a billion samples, it becomes unreasonable thing to do. \n",
    "\n",
    "So, if we cannot make ngram dataset ourselves, it sounds reasonable to take already existing one. However here we face another problem, ideally we need free, general-purpose ngrams that are large enough to highlight common dependencies. This task was not as easy as it seems like, as calculating ngrams is a difficult task and most of datasets are private and have paid-access. There exist some services such as [Public n-gram data](https://www.ngrams.info/download_coca.asp), however I faced difficulties accessing anything from there.\n",
    "\n",
    "Given all this problems above, I decided to still use [Publoc n-gram data](https://www.ngrams.info/download_coca.asp) that is given us with current assignment - bigrams. Why not 5-grams? Because they contain less information in general. For some reason 5-grams dataset contain in total of 16451820 different samples, when bigrams have 286758206 (17 times more info!). For that reason, even thought bigrams do not capture long dependencies, they still more preferable, and with their heigher unique word count, they seems to be applicable in more texts.\n",
    "\n",
    "\n",
    "### N-gram LM specifics\n",
    "\n",
    "Basically my implementation is slight improvement over Norvig solution. The key difference - we use ngram for context-specific suggesitons.\n",
    "\n",
    "The algorithm principle is simple. If we already have \"pretrained\" language model, we can use it to calculate probabillity of seing some given word. If this probability is high enough, we can suppose that the word is correct. However if it is not, we can apply some edits (Novig's idea) and then find not just most frequent token, but most frequent in given context (there are also some edge cases when all edits are not present, then we find edit in raw vocab (idea of backoff), and if not found again, suppose initial word is correct). This solution should add context-dependency to Novig solution and make algorithm more robust overall.\n",
    "\n",
    "However as it is still same idea. In addition used dataset do not capture long dependencies, so not much improvement would be seen.\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "The only two hyperparameters we can tune are `freq_threshold` and `edit_lim` (minimum threshold needed to be achieved for word not to be corrected, maximum edit distance). \n",
    "\n",
    "Even though `edit_lim` is not bound, any value greater than 3 takes minutes to compute, so in some sort `3` is limit. My experiments showed that `2` is optimal, however for faster computation I am going to use `1` in evaluation step. \n",
    "\n",
    "And speaking about `freq_threshold`, value of `0` means we will accept any word if it is possible in context, and value of `1` will try to correct each word in a text. I found that value between `1e-6` and `5e-6` provides more optimal result (I tuned it on my own examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46rk65S4GRSe"
   },
   "source": [
    "## Evaluate on a test set\n",
    "\n",
    "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OwZWaX9VVs7B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-22 02:59:20--  https://huggingface.co/datasets/vishnun/SpellGram/resolve/main/train.csv\n",
      "Resolving huggingface.co (huggingface.co)... 108.138.189.74, 108.138.189.96, 108.138.189.57, ...\n",
      "Connecting to huggingface.co (huggingface.co)|108.138.189.74|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4489429 (4,3M) [text/plain]\n",
      "Saving to: ‘data/eval.csv’\n",
      "\n",
      "data/eval.csv       100%[===================>]   4,28M  3,10MB/s    in 1,4s    \n",
      "\n",
      "2024-03-22 02:59:22 (3,10 MB/s) - ‘data/eval.csv’ saved [4489429/4489429]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://huggingface.co/datasets/vishnun/SpellGram/resolve/main/train.csv\" -O \"data/eval.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rate the silent upeaker four out oe 6</td>\n",
       "      <td>rate the silent speaker four out of 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please find me tqe gork tqe bfrning sorld</td>\n",
       "      <td>please find me the work the burning world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three friendl afe relaxing uround the tsble</td>\n",
       "      <td>three friends are relaxing around the table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what dm they want</td>\n",
       "      <td>what do they want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man in tan aat working with stones</td>\n",
       "      <td>man in tan hat working with stones</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        source  \\\n",
       "0        rate the silent upeaker four out oe 6   \n",
       "1    please find me tqe gork tqe bfrning sorld   \n",
       "2  three friendl afe relaxing uround the tsble   \n",
       "3                            what dm they want   \n",
       "4           man in tan aat working with stones   \n",
       "\n",
       "                                        target  \n",
       "0        rate the silent speaker four out of 6  \n",
       "1    please find me the work the burning world  \n",
       "2  three friends are relaxing around the table  \n",
       "3                            what do they want  \n",
       "4           man in tan hat working with stones  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv('data/eval.csv').iloc[:2000]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|██████████████████| 2000/2000 [00:17<00:00, 113.35it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for _, row in tqdm(df.iterrows(),  total=df.shape[0], desc=f'Running evaluation'):\n",
    "    predictions.append(sp.check_correct(row['source']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|███████████████████| 2000/2000 [00:57<00:00, 34.95it/s]\n"
     ]
    }
   ],
   "source": [
    "norvig_predictions = []\n",
    "norvig = NorvigSolution('data/bigrams.txt')\n",
    "for _, row in tqdm(df.iterrows(),  total=df.shape[0], desc=f'Running evaluation'):\n",
    "    norvig_predictions.append(' '.join(norvig.correction(word) for word in row['source'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, targets, sources):\n",
    "    total = 0\n",
    "    confusion = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n",
    "    \n",
    "    for pred, target, source in zip(predictions, targets, sources):\n",
    "        for p, t, s in zip(pred.split(), target.split(), source.split()):\n",
    "            \n",
    "            if p == t and t == s:\n",
    "                confusion['TP'] += 1\n",
    "            elif p == t:\n",
    "                confusion['TN'] += 1\n",
    "            elif t == s:\n",
    "                confusion['FP'] += 1\n",
    "            else:\n",
    "                confusion['FN'] += 1\n",
    "                \n",
    "            total += 1\n",
    "    \n",
    "    return confusion, total\n",
    "\n",
    "\n",
    "def print_confusion(confusion: dict, total: int, round_f: int = 4):\n",
    "    print(f\"== Confusion matrix ==\")\n",
    "    print(*[\n",
    "        [confusion['TP'], confusion['FP']], \n",
    "        [confusion['FN'], confusion['TN']]\n",
    "    ], sep='\\n')\n",
    "    print()\n",
    "    \n",
    "    accuracy = (confusion['TP'] + confusion['TN']) / total\n",
    "    precision = confusion['TP'] / (confusion['TP'] + confusion['FP'])\n",
    "    recall = confusion['TP'] / (confusion['TP'] + confusion['FN'])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    print('Accuracy: ', round(accuracy, round_f), sep='\\t')\n",
    "    print('Precision:', round(precision, round_f), sep='\\t')\n",
    "    print('Recall:   ', round(recall, round_f), sep='\\t')\n",
    "    print('F1:       ', round(f1, round_f), sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Confusion matrix ==\n",
      "[14263, 659]\n",
      "[1444, 3166]\n",
      "\n",
      "Accuracy: \t0.8923\n",
      "Precision:\t0.9558\n",
      "Recall:   \t0.9081\n",
      "F1:       \t0.9313\n"
     ]
    }
   ],
   "source": [
    "confusion, total = evaluate(predictions, df['target'], df['source'])\n",
    "\n",
    "print_confusion(confusion, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Confusion matrix ==\n",
      "[14511, 411]\n",
      "[1911, 2699]\n",
      "\n",
      "Accuracy: \t0.8811\n",
      "Precision:\t0.9725\n",
      "Recall:   \t0.8836\n",
      "F1:       \t0.9259\n"
     ]
    }
   ],
   "source": [
    "confusion, total = evaluate(norvig_predictions, df['target'], df['source'])\n",
    "\n",
    "print_confusion(confusion, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Confusion matrix ==\n",
      "[14922, 0]\n",
      "[4610, 0]\n",
      "\n",
      "Accuracy: \t0.764\n",
      "Precision:\t1.0\n",
      "Recall:   \t0.764\n",
      "F1:       \t0.8662\n"
     ]
    }
   ],
   "source": [
    "confusion, total = evaluate(df['source'], df['target'], df['source'])\n",
    "\n",
    "print_confusion(confusion, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation dataset choice\n",
    "\n",
    "I decided to use [SpellGram](https://huggingface.co/datasets/vishnun/SpellGram/resolve/main/train.csv) dataset for evaluation. It provide several benefits, such as data is already tokenized in the same way as \"training\" data, and it was specifially designed for n-grams. In addition it is also general-purpose and has a lot of samples we can work with. Due to the fact that I already trained model, I decided to use [Spellgram training data](https://huggingface.co/datasets/vishnun/SpellGram/resolve/main/train.csv) for eval. And as models are slow, I just cut data for faster evaluation.\n",
    "\n",
    "### Results\n",
    "\n",
    "As we can see, both Norvig solution and my perform better than no replacement at all. However some interesting pattern occurs. Even thought accorging to accuracy and f1-score n-gram solution is better, it is not that significat as jump from no-edit. \n",
    "\n",
    "In addition we can see that precision seems to decrease the more complex model we build. This potentially mean that `freq_threshold` is still a bit high, so further tuning could be done.\n",
    "\n",
    "Opposite to precision, recall is getting heigher. This indicates that when model corrects any word, it is more \"sure\" that the answer is indeed correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "Work done by Polina Zelenskaya (DS21-01)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
